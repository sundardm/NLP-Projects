{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages you may need to import\n",
    "from sklearn.datasets import load_files\n",
    "from scipy.stats import uniform, randint as sp_randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,RandomizedSearchCV, GridSearchCV\n",
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the categories\n",
    "categories = ['neg', 'pos']\n",
    "\n",
    "# Load the dataset\n",
    "docs_to_train = load_files(\"/Users/MSD/OneDrive - Dartmouth College/189/Assg4/aclImdb/train\", description=None, categories=categories, load_content=True, shuffle=True, encoding='utf-8', decode_error='strict', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = docs_to_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_to_train.target_names #0 is negative and 1 is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_raw = docs_to_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data type is <class 'list'> and the length of the raw text data is, 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"The data type is\", type(text_raw), \"and the length of the raw text data is,\", len(text_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification for preprocessing: \n",
    "\n",
    "I remove punctuation within my document. I then remove anything other than an alphabet/number. Since I remove punctuation and tokenized my data, I remove words smaller than 3 characters to remove the \"noise\" from the document. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and other characters as defined by me\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "text_ready = []\n",
    "\n",
    "\n",
    "#stopw = stopwords.words('english') + list(string.punctuation)  +[\"’\",\"”\",\"—\",\"“\"] \n",
    "stopw = list(string.punctuation)  +[\"’\",\"”\",\"—\",\"“\"] \n",
    "\n",
    "for i in range(0,len(text_raw)):\n",
    "    x = text_raw[i]\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', x)\n",
    "    \n",
    "   \n",
    "    #Words\n",
    "    tokens = [stop for stop in word_tokenize(text.lower()) if stop not in stopw] #removes stopwords, punctuation and custom filter\n",
    "    tokens = [w for w in tokens if re.findall(r\"(\\w{3})\",w) ] #removes anything less than 3 characters\n",
    "    review = ' '.join(tokens)\n",
    "    text_ready.append(review)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clichés, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_raw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'words can describe how bad this movie can explain writing only you have too see for yourself get grip how horrible movie really can not that recommend you that there are many clich mistakes and all other negative things you can imagine here that will just make you cry start with the technical first there are lot mistakes regarding the airplane won list them here but just mention the coloring the plane they didn even manage show airliner the colors fictional airline but instead used 747 painted the original boeing livery very bad the plot stupid and has been done many times before only much much better there are many ridiculous moments here that lost count really early also was the bad guys side all the time the movie because the good guys were stupid executive decision should without doubt you choice over this one even the turbulence movies are better fact every other movie the world better than this one'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ready[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text,X_test_text,y_train,y_test=train_test_split(text_ready,\n",
    "                                              y_raw ,\n",
    "                                              test_size=0.1,\n",
    "                                                train_size = 0.4,\n",
    "                                               stratify = y_raw,\n",
    "                                              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives reviews 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of positives reviews\", len(y_train[y_train == 1])) #pos reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative reviews 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of negative reviews\", len(y_train[y_train ==0])) #neg reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification for CountVectorizer:\n",
    "\n",
    "In my opinion, I think we should ignore 1 grams and consider batch of words that might be the decider in whether a review is positive to negative. Phrases like \"really good\", \"really bad\". I will find out whether this is valid. I limit my features to 50,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "vect=CountVectorizer(ngram_range = (2,3)).fit(X_train_text)\n",
    "X_train = vect.transform(X_train_text)\n",
    "X_test = vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows are,  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of rows are, \", X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features are,  2254415\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of features are, \", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000 000',\n",
       " '000 000 000',\n",
       " '000 000 and',\n",
       " '000 000 could',\n",
       " '000 000 give',\n",
       " '000 000 hollow',\n",
       " '000 000 marries',\n",
       " '000 000 mega',\n",
       " '000 000 prison',\n",
       " '000 000 retitled',\n",
       " '000 000 stupid',\n",
       " '000 000 the',\n",
       " '000 000 times',\n",
       " '000 250',\n",
       " '000 250 000',\n",
       " '000 advance',\n",
       " '000 advance goes',\n",
       " '000 after',\n",
       " '000 after cohn',\n",
       " '000 and']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSD\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy score from our 5 fold cross validation is,  75.77 % from LR\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "model=LogisticRegression(C=0.001)\n",
    "k_fold = StratifiedKFold(5,random_state = 9)\n",
    "scores = cross_val_score(model,X_train,y_train,cv =k_fold,scoring = \"accuracy\")\n",
    "print('The mean accuracy score from our 5 fold cross validation is, ', round(scores.mean()*100,2) ,'% from LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = [(\"lr\",LogisticRegression())]  #Feature Scaling and SVM classifier\n",
    "lr1 = Pipeline(lr)  #Pipeline\n",
    "param_lr1 = [{ \"lr__C\":[0.001, 0.01, 0.1, 1, 10]}]\n",
    "grid_lr = GridSearchCV(lr1,param_grid = param_lr1,cv = 5,scoring = \"accuracy\",verbose = 3, n_jobs = -1) #GridSearch and parameter grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  25 | elapsed:   35.4s remaining:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  25 | elapsed:  1.2min remaining:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.3min finished\n",
      "C:\\Users\\MSD\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'lr__C': [0.001, 0.01, 0.1, 1, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy score from our 5 fold cross validation is,  82.99 % from LR\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy score from our 5 fold cross validation is, ', round(grid_lr.best_score_*100,2) ,'% from LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = grid_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is,  84.84 % from LR\n",
      "The precision is,  83.84 % from LR\n",
      "The recall is,  86.32 % from LR\n",
      "The F1 score is,  85.06 % from LR\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is, ', round(accuracy_score(y_test,pred2)*100,2) ,'% from LR')\n",
    "print('The precision is, ', round(precision_score(y_test,pred2)*100,2) ,'% from LR')\n",
    "print('The recall is, ', round(recall_score(y_test,pred2)*100,2) ,'% from LR')\n",
    "print('The F1 score is, ', round(f1_score(y_test,pred2)*100,2) ,'% from LR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1042,  208],\n",
       "       [ 171, 1079]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification:\n",
    "\n",
    "After hyperparameterizing y Logisitic Regression model, the results were\n",
    "\n",
    "\n",
    "\n",
    "The accuracy is,  84.84 % from LR\n",
    "The precision is,  83.84 % from LR\n",
    "The recall is,  86.32 % from LR\n",
    "The F1 score is,  85.06 % from LR\n",
    "\n",
    "Understandably, my assumption about ignoring 1 grams was misplaced. This may be due to people not typing the same way so not all phrases are common across reviews. Additionally, I will have to remove numbers as they also count as noise and take away from the intrepretability of the model. Additionally, I will incorporate stop words that will help me get to the core of each review and determine its sentiment. I will also Stem the words using snowball stemmer to help me arrive at the core of a word which generally should help. I also noticed a lot of noisy words like \"aaa\" \"bbb\" which don't add anything to the model. I will remove words with 3 or more duplicate characters. This will not affect words like \"good\" but will remove the terms like \"trashhhh\". \n",
    "\n",
    "After these preprocessing changes, I will run it through a TFID vectorizer with ngram(1,5) and consider words more than a frequency of 10 or more. This vector result will be put down a Deep Learning Neural Network model. The parameters used in that model is out of scope for this assignment and will not be explained further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and other characters as defined by me\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "text_ready = []\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stem = SnowballStemmer(\"english\")\n",
    "\n",
    "stopw = stopwords.words('english') + list(string.punctuation)  +[\"’\",\"”\",\"—\",\"“\"]\n",
    "\n",
    "\n",
    "for i in range(0,len(text_raw)):\n",
    "    x = text_raw[i]\n",
    "    text = re.sub(r'((.)\\2{2,})', ' ', x) #remove three or more consecutive characters like 'trashhhh'\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "   \n",
    "    #Words\n",
    "    tokens = [stop for stop in word_tokenize(text.lower()) if stop not in stopw] #removes stopwords, punctuation and custom filter\n",
    "    #tokens = [w for w in tokens if w.isalpha()]  #remove every that is not fully alphabetic\n",
    "    tokens = [w for w in tokens if re.findall(r\"(\\w{3})\",w) ] #removes anything less than 3 characters\n",
    "    tokens = [stem.stem(w) for w in tokens]\n",
    "    review = ' '.join(tokens)\n",
    "    text_ready.append(review)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text,X_test_text,y_train,y_test=train_test_split(text_ready,\n",
    "                                              y_raw ,\n",
    "                                              test_size=0.1,\n",
    "                                                train_size = 0.4,\n",
    "                                               stratify = y_raw,\n",
    "                                              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write your code here\n",
    " # vectorise & transform\n",
    "vect = TfidfVectorizer(min_df=10,ngram_range=(1,5)).fit(X_train_text)\n",
    "X_train_vectorized = vect.transform(X_train_text)\n",
    "X_test_vectorized = vect.transform(X_test_text)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10000/10000 [==============================] - 2s 172us/step - loss: 0.5573 - acc: 0.7746\n",
      "Epoch 2/2\n",
      "10000/10000 [==============================] - 2s 152us/step - loss: 0.2458 - acc: 0.9174\n",
      "2500/2500 [==============================] - 0s 182us/step\n",
      "\n",
      "acc: 89.44%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Embedding, Convolution1D, GlobalMaxPooling1D\n",
    "from keras import layers, models, callbacks, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    " \n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(16322,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='RMSProp',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train_vectorized, y_train, epochs=2, batch_size=250)\n",
    "\n",
    "scores = model.evaluate(X_test_vectorized, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is,  89.44 % from the Neural Network\n",
      "The precision is,  89.89 % from the Neural Network\n",
      "The recall is,  88.88 % from the Neural Network\n",
      "The F1 score is,  89.38 % from the Neural Network\n"
     ]
    }
   ],
   "source": [
    "pred_nn = model.predict(X_test_vectorized)\n",
    "pred_nn = (pred_nn >= 0.5)\n",
    "print('The accuracy is, ', round(accuracy_score(y_test,pred_nn)*100,2) ,'% from the Neural Network')\n",
    "print('The precision is, ', round(precision_score(y_test,pred_nn)*100,2) ,'% from the Neural Network')\n",
    "print('The recall is, ', round(recall_score(y_test,pred_nn)*100,2) ,'% from the Neural Network')\n",
    "print('The F1 score is, ', round(f1_score(y_test,pred_nn)*100,2) ,'% from the Neural Network')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the results are greatly improved. Further improvement can be made by considering an Embedding layer and Convolution1D and MaxPooling parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Latent Dirichlet Allocation Simple Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_LDA_results(lda_model, feature_names, n_top_words=15):\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        message = \"Topic %d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "vect2=CountVectorizer(max_df = 0.15, max_features = 10000)\n",
    "X_train2 = vect2.fit_transform(X_train_text)\n",
    "X_test2 = vect2.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components = 10, learning_method = 'batch', max_iter = 30, random_state = 9).fit(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: famili son father role oscar nomin mother award live boy indian day american georg real\n",
      "\n",
      "Topic 1: comedi origin music funni cast version enjoy anim role fun song book wonder star fan\n",
      "\n",
      "Topic 2: game jane role western jame star cast stewart novel robert john real seri jim bond\n",
      "\n",
      "Topic 3: murder kill polic wife cop killer john role car turn crime michael father town harri\n",
      "\n",
      "Topic 4: beauti world live point differ real may emot human audienc without viewer view fact quit\n",
      "\n",
      "Topic 5: war action world fight american star soldier human new hero effect set earth sci seri\n",
      "\n",
      "Topic 6: episod girl young woman mother music season seri husband danc old daughter women famili new\n",
      "\n",
      "Topic 7: guy noth worst minut funni got wast laugh go bore thought stupid line aw everi\n",
      "\n",
      "Topic 8: paul role cast page betti smith young ann che mari job henri jeff harri friend\n",
      "\n",
      "Topic 9: horror kill effect zombi hous gore killer blood night pretti dead budget girl scari set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_LDA_results(lda_model, feature_names, n_top_words=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output names seem pretty good. Some of the results provide very little clue towards the title of the review topic, as it could apply to a number of topics. For Topic 5, I would guess a war/action film that features sci-fi, topic 9 as your run of the mill horror film featuring zombies, topic 2 is a western setting topic/movie, topic 2 is refers to an animated movie topic. \n",
    "\n",
    "Note: I used the data from my improved model with the new pre-processing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
